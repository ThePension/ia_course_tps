{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IA : CP1\n",
    "- Aubert Nicolas,\n",
    "- ISC3il-b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "# Charger les fichiers depuis le répertoire data en utilisant la méthode load_files() du package sklearn.datasets.\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "# Charger les données (./exo1/data')\n",
    "data = load_files(\"./exo1/data/\")\n",
    "\n",
    "print(data.target_names)\n",
    "\n",
    "# Diviser les données en train et test avec une répartition de 70-30%.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=0)\n",
    "\n",
    "# Load les données de test (./exo1/data/test.csv')\n",
    "data_test = load_files(\"./exo1/data/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best score: 0.919\n",
      "0.89\n",
      "Classification report for Bayes : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.92      0.86      0.89       303\n",
      "         pos       0.87      0.92      0.89       297\n",
      "\n",
      "    accuracy                           0.89       600\n",
      "   macro avg       0.89      0.89      0.89       600\n",
      "weighted avg       0.89      0.89      0.89       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implémenter avec Bayes un Gridsearch avec une cross validation de 5 folders comme suit \n",
    "# use_idf : (True, False),\n",
    "# ii. alpha : (1e-2, 1e-3)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    " \n",
    "parameters = {\n",
    "    'vect__use_idf': (True, False),\n",
    "    'clf__alpha': (1e-2, 1e-3)\n",
    "}\n",
    "\n",
    "# Créer un pipeline avec un TfidfVectorizer() et un MultinomialNB().\n",
    "# Utiliser le GridSearchCV pour trouver les meilleurs paramètres.\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Afficher les meilleurs paramètres de la cross-validation de chaque modèle.\n",
    " \n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "\n",
    "# Afficher le score de précision sur le jeu de test.\n",
    " \n",
    "print(grid_search.score(X_test, y_test))\n",
    "\n",
    "# Interpréter les valeurs trouvées dans use_idf.\n",
    "\n",
    "# use_idf : (True, False) : True est meilleur que False\n",
    "\n",
    "# Evaluer le modèle Bayes avec le dataset de test.\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print(\"Classification report for Bayes : \\n\")\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'clf__C': 5, 'vect__use_idf': True}\n",
      "0.9316666666666666\n",
      "Best score: 0.924\n",
      "Classification report for SVM : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.94      0.92      0.93       303\n",
      "         pos       0.92      0.94      0.93       297\n",
      "\n",
      "    accuracy                           0.93       600\n",
      "   macro avg       0.93      0.93      0.93       600\n",
      "weighted avg       0.93      0.93      0.93       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implémenter avec SVM un Gridsearch avec une cross validation de 5 folders, avec les paramètres suivants :\n",
    "# use_idf: (True, False),\n",
    "# ii. C: [0.1,1,5]\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    " \n",
    "parameters = {\n",
    "    'vect__use_idf': (True, False),\n",
    "    'clf__C': [0.1,1,5]\n",
    "}\n",
    "\n",
    "# Créer un pipeline avec un TfidfVectorizer() et un LinearSVC().\n",
    "# Utiliser le GridSearchCV pour trouver les meilleurs paramètres.\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Afficher les meilleurs paramètres trouvés par le GridSearchCV.\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Afficher le score de précision sur le jeu de test.\n",
    "\n",
    "print(grid_search.score(X_test, y_test))\n",
    "\n",
    "# Afficher le meilleur score de cross validation.\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "\n",
    "# Interpréter les valeurs trouvées dans use_idf.\n",
    "\n",
    "# use_idf : (True, False) : True est meilleur que False\n",
    "\n",
    "# Interpréter la valeur trouvée de C dans le cas de SVM.\n",
    "\n",
    "# C : [0.1,1,5] : 5 est meilleur que 1 et 0.1\n",
    "\n",
    "# Evaluer le modèle SVM avec le dataset de test.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print(\"Classification report for SVM : \\n\")\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluation des modèles\n",
    "\n",
    "SVM donne de meilleurs résultats que Bayes.\n",
    "\n",
    "### Y-avait-il du surentrainement (overfitting) ? pourquoi ?\n",
    "\n",
    "\n",
    "\n",
    "### Interpréter les résultats des f1_score.\n",
    "\n",
    "Le f1_score de SVM est plus élevé que celui de Bayes. Cela signifie que SVM est plus précis que Bayes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2 : Régression\n",
    "\n",
    "Le but de ce régresseur est de prédire les classes de prix (0, 1, 2, 3) des téléphones portables à partir de leurs caractéristiques techniques (puissance de la batterie, couleurs, mémoire, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
      "0            842     0          2.2         0   1       0           7    0.6   \n",
      "1           1021     1          0.5         1   0       1          53    0.7   \n",
      "2            563     1          0.5         1   2       1          41    0.9   \n",
      "3            615     1          2.5         0   0       0          10    0.8   \n",
      "4           1821     1          1.2         0  13       1          44    0.6   \n",
      "5           1859     0          0.5         1   3       0          22    0.7   \n",
      "6           1821     0          1.7         0   4       1          10    0.8   \n",
      "7           1954     0          0.5         1   0       0          24    0.8   \n",
      "8           1445     1          0.5         0   0       0          53    0.7   \n",
      "9            509     1          0.6         1   2       1           9    0.1   \n",
      "\n",
      "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
      "0        188        2  ...         20       756  2549     9     7         19   \n",
      "1        136        3  ...        905      1988  2631    17     3          7   \n",
      "2        145        5  ...       1263      1716  2603    11     2          9   \n",
      "3        131        6  ...       1216      1786  2769    16     8         11   \n",
      "4        141        2  ...       1208      1212  1411     8     2         15   \n",
      "5        164        1  ...       1004      1654  1067    17     1         10   \n",
      "6        139        8  ...        381      1018  3220    13     8         18   \n",
      "7        187        4  ...        512      1149   700    16     3          5   \n",
      "8        174        7  ...        386       836  1099    17     1         20   \n",
      "9         93        5  ...       1137      1224   513    19    10         12   \n",
      "\n",
      "   three_g  touch_screen  wifi  price_range  \n",
      "0        0             0     1            1  \n",
      "1        1             1     0            2  \n",
      "2        1             1     0            2  \n",
      "3        1             0     0            2  \n",
      "4        1             1     0            1  \n",
      "5        1             0     0            1  \n",
      "6        1             0     1            3  \n",
      "7        1             1     1            0  \n",
      "8        1             0     0            0  \n",
      "9        1             0     0            0  \n",
      "\n",
      "[10 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. Lire les données du répertoire data dans un dataframe Pandas et afficher les premiers 10 lignes des données de train.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "df = pd.read_csv(\"./exo2/data/train.csv\")\n",
    "\n",
    "print(df.head(10))\n",
    "\n",
    "# 2. Enlever depuis les données de train les lignes où la colonne px_height est nulle.\n",
    "\n",
    "df = df[df['px_height'].notnull()]\n",
    "\n",
    "# 3. Diviser les données en train et test.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('price_range', axis=1), df['price_range'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1, accuracy = 0.893333\n",
      "k = 2, accuracy = 0.890000\n",
      "k = 3, accuracy = 0.910000\n",
      "k = 4, accuracy = 0.906667\n",
      "k = 5, accuracy = 0.925000\n",
      "k = 6, accuracy = 0.933333\n",
      "k = 7, accuracy = 0.943333\n",
      "k = 8, accuracy = 0.936667\n",
      "k = 9, accuracy = 0.940000\n",
      "k = 10, accuracy = 0.935000\n",
      "k = 11, accuracy = 0.938333\n",
      "k = 12, accuracy = 0.940000\n",
      "k = 13, accuracy = 0.938333\n",
      "k = 14, accuracy = 0.941667\n",
      "k = 15, accuracy = 0.941667\n",
      "k = 16, accuracy = 0.941667\n",
      "k = 17, accuracy = 0.936667\n",
      "k = 18, accuracy = 0.946667\n",
      "k = 19, accuracy = 0.943333\n",
      "Best k = 18 with accuracy = 0.946667\n"
     ]
    }
   ],
   "source": [
    "# 4. Utiliser un KNN classifier (KNeighborsClassifier) pour faire une première classification. Comment vous choisissez le k.\n",
    "\n",
    "# Find the best k parameter\n",
    "\n",
    "# Initialize a dict to store the accuracies for each value of k\n",
    "accuracies = {}\n",
    "\n",
    "for k in range(1, 20):\n",
    "    # initialize the classifier\n",
    "    clf = KNeighborsClassifier(k, weights='uniform')\n",
    "\n",
    "    # train it with the 'fit' method (you should pass the training set and the related labels)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # compute the predictions using the test set\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    # Compute the accuracy of the classification\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    accuracies[k] = accuracy\n",
    "\n",
    "# Print the accuracies for each value of k\n",
    "for k, accuracy in accuracies.items():\n",
    "    print(\"k = %d, accuracy = %f\" % (k, accuracy))\n",
    "\n",
    "# print the best k\n",
    "best_k = max(accuracies, key=accuracies.get)\n",
    "print(\"Best k = %d\" % best_k, \"with accuracy = %f\" % accuracies[best_k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9466666666666667\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "{'clf__C': 5, 'clf__kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       151\n",
      "           1       0.94      0.94      0.94       135\n",
      "           2       0.95      0.93      0.94       151\n",
      "           3       0.98      0.98      0.98       163\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# 5. Afficher le score de précision sur le jeu de test.\n",
    " \n",
    "print(knn.score(X_test, y_test))\n",
    "\n",
    "# 5. Implémenter un pipeline SVM avec un scaler de votre choix.\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', SVC()),\n",
    "])\n",
    "\n",
    "# 6. Chercher avec un gridsearch de votre choix les meilleurs paramètres de votre SVM.\n",
    "\n",
    "parameters = {\n",
    "    'clf__C': [0.1,1,5],\n",
    "    'clf__kernel': ['linear', 'rbf', 'poly'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# 7. Afficher le rapport d’évaluation après l’évaluation des données de test.\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree score : 0.821667\n",
      "Forest Tree score : 0.853333\n"
     ]
    }
   ],
   "source": [
    "# 9. Facultatif : implémenter un arbre de décision puis un Forest Tree (from sklearn.ensemble import RandomForestClassifier) (+3 pts)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Decision Tree score : %f\" % tree.score(X_test, y_test))\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"Forest Tree score : %f\" % forest.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La précision moyenne est de 0.96\n",
    "\n",
    "- Le Forest Tree (0.88) est meilleur que le Decision Tree (0.83)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
